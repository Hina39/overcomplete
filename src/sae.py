import pathlib

import numpy as np
import torch
from einops import rearrange

# https://github.com/KempnerInstitute/overcomplete/blob/main/overcomplete/sae/topk_sae.py#L11
from overcomplete.metrics import r2_score
from overcomplete.models import DinoV2, ResNet
from overcomplete.sae import TopKSAE, train_sae
from torch.utils.data import DataLoader, TensorDataset
from torchvision import datasets, transforms
from torchvision.transforms import Compose
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Dataloader
transform_resnet = Compose(
    [transforms.Resize(
    (224, 224),
    interpolation=transforms.InterpolationMode.BICUBIC, antialias=True),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5],
                        std=[0.5, 0.5, 0.5])
    ]
)

transform_dino = Compose(
            [transforms.Resize(
                (224, 224),
                interpolation=transforms.InterpolationMode.BICUBIC, antialias=True),
             transforms.ToTensor(),
             transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                  std=[0.229, 0.224, 0.225])])

dataset = datasets.ImageFolder(
    root=pathlib.Path("data/imagenet/train"), transform=transform_resnet
)

model = ResNet(device='cuda')

z_dict = {}
dictionary_all = []
for class_name, class_idx in tqdm(dataset.class_to_idx.items()):
    # æŒ‡å®šã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åé›†ã™ã‚‹
    indices = [i for i, (_, target) in enumerate(dataset.samples) if target == class_idx]
    if not indices:
        continue  # ã‚µãƒ³ãƒ—ãƒ«ãŒãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼
    
    # è©²å½“ã‚¯ãƒ©ã‚¹ã®Subsetã‚’ä½œæˆã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ç”¨æ„
    subset = torch.utils.data.Subset(dataset, indices)
    subset_loader = DataLoader(subset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)
    
    images_list = []
    for images, _ in subset_loader:
        images_list.append(images)

    # ãƒãƒƒãƒã”ã¨ã«é€£çµã—ã¦GPUã¸
    images_class = torch.cat(images_list, dim=0).cuda()
    print(images_class.shape) # torch.Size([1300, 3, 224, 224])
    # forward_featuresã§ç‰¹å¾´æŠ½å‡º
    activations = model.forward_features(images_class)
    print(activations.shape) # torch.Size([1300, 2048, 7, 7])

    Activations = rearrange(activations, 'n c h w -> (n h w) c')
    print(f"ã‚¯ãƒ©ã‚¹ {class_name}: Activations shape = {Activations.shape} ğŸ˜„")

    sae = TopKSAE(Activations.shape[-1], nb_concepts=10, top_k=2, device='cuda')

    dataloader = torch.utils.data.DataLoader(TensorDataset(Activations), batch_size=1024, shuffle=True)
    optimizer = torch.optim.Adam(sae.parameters(), lr=5e-4)

    def criterion(x, x_hat, pre_codes, codes, dictionary):
        """saeã®æå¤±é–¢æ•°."""
        mse = (x - x_hat).square().mean()
        return mse

    logs = train_sae(sae, dataloader, criterion, optimizer, nb_epochs=20, device='cuda')
    # print(logs)

    sae = sae.eval()
    with torch.no_grad():
        # codesãŒZã«ã‚ãŸã‚‹ï¼ã‚¹ãƒ‘ãƒ¼ã‚¹ãªçµ„ã¿åˆã‚ã›ä¿‚æ•°
        pre_codes, z_topk = sae.encode(Activations)
        # Zã‚’ä¿å­˜
        # np.savez("z.npz", z_topk.cpu().detach().numpy())
        z_dict[class_name] = z_topk.cpu().detach().numpy() # ã‚¯ãƒ©ã‚¹ã®ãƒ©ãƒ™ãƒ«ã‚’ã‚­ãƒ¼ã«ã—ã¦ä¿å­˜
        print(z_topk.shape) # torch.Size([63700, 10])
        # print(z_topk)

        # ã“ã“ã®å‡ºåŠ›ã¯ã‚ˆãã‚ã‹ã‚‰ã‚“
        _, codes, recons = sae(Activations)
        print('R2', r2_score(Activations, recons).item())

    # è¾æ›¸ã¯ã“ã®ã‚ˆã†ã«ã—ã¦ç²å¾—ã§ãã‚‹
    dictionary = sae.get_dictionary()
    dictionary_all.append(dictionary)
    # è¾æ›¸ã‚’ä¿å­˜ã€€(GPU â†’ CPU â†’ NumPyå¤‰æ›)
    # np.savez("dictionary.npz", dictionary.cpu().detach().numpy())
    print(dictionary.shape) #(ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®æ•°,ã€€ç‰¹å¾´é‡ã®æ¬¡å…ƒæ•°)

np.savez("outputs/topk_sae/z_dict.npz", **z_dict) # è¾æ›¸ã‚’ä¿å­˜

dictionary_all_cat = torch.cat(dictionary_all, dim=0)  # è¾æ›¸ã¯æ¨ªæ–¹å‘ã«é€£çµã™ã‚‹å ´åˆ
np.savez("outputs/topk_sae/dictionary.npz", dictionary_all_cat.cpu().detach().numpy())
print(dictionary_all_cat.shape)
print("Finish!ğŸ¤©")


"""
ã“ã“ã‹ã‚‰ä¸‹ã¯ã‚¯ãƒ©ã‚¹ã”ã¨ã®è¨ˆç®—ã‚’è€ƒæ…®ã—ãªã„å ´åˆã®ã‚³ãƒ¼ãƒ‰
"""

#ä¾‹ãˆã°ã€"00000"ã‚¯ãƒ©ã‚¹ã®ç”»åƒã ã‘ä½¿ã„ãŸã„å ´åˆ
# target_class = "00000"
# target_idx = dataset.class_to_idx[target_class]
# dataset.samples = [s for s in dataset.samples if s[1] == target_idx]
# dataset.targets = [target_idx for _ in dataset.samples]

# dataloader = DataLoader(
#     dataset,
#     batch_size=32,
#     shuffle=False,
#     num_workers=4,
#     pin_memory=True,
# )

# images = []
# for i, (image, _) in enumerate(dataloader):
#     # print(image.shape)
#     images.append(image)


# images = torch.cat(images, dim=0).cuda()  # concatenate along batch dimension
# print(images.shape) # torch.Size([1300, 3, 224, 224])

# # ok then forward and flatten to get the tokens
# Activations = model.forward_features(images)

# # Activations = rearrange(Activations, 'n t d -> (n t) d')
# # print(Activations.shape) # torch.Size([81920, 384])

# Activations = rearrange(Activations, 'n c h w -> (n h w) c')
# print(Activations.shape) # torch.Size([63700, 2048])

# sae = TopKSAE(Activations.shape[-1], nb_concepts=10, top_k=2, device='cuda')

# """
# top_k : int, optional
#         Number of top activations to keep in the latent representation,
#         by default n_components // 10 (sparsity of 90%).
# """

# dataloader = torch.utils.data.DataLoader(TensorDataset(Activations), batch_size=1024, shuffle=True)
# optimizer = torch.optim.Adam(sae.parameters(), lr=5e-4)

# def criterion(x, x_hat, pre_codes, codes, dictionary):
#   """
#   saeã®æå¤±é–¢æ•°
#   """
#   mse = (x - x_hat).square().mean()
#   return mse

# logs = train_sae(sae, dataloader, criterion, optimizer, nb_epochs=20, device='cuda')
# print(logs)

# sae = sae.eval()

# from overcomplete.metrics import r2_score
# with torch.no_grad():
#     # codesãŒZã«ã‚ãŸã‚‹ï¼ã‚¹ãƒ‘ãƒ¼ã‚¹ãªçµ„ã¿åˆã‚ã›ä¿‚æ•°
#     pre_codes, z_topk = sae.encode(Activations)
#     # Zã‚’ä¿å­˜
#     np.savez("z.npz", z_topk.cpu().detach().numpy())
#     print(z_topk.shape) # torch.Size([63700, 10])
#     print(z_topk)

#     # ã“ã“ã®å‡ºåŠ›ã¯ã‚ˆãã‚ã‹ã‚‰ã‚“
#     _, codes, recons = sae(Activations)
#     print('R2', r2_score(Activations, recons).item())

# # è¾æ›¸ã¯ã“ã®ã‚ˆã†ã«ã—ã¦ç²å¾—ã§ãã‚‹
# dictionary = sae.get_dictionary()
# # è¾æ›¸ã‚’ä¿å­˜ã€€(GPU â†’ CPU â†’ NumPyå¤‰æ›)
# np.savez("dictionary.npz", dictionary.cpu().detach().numpy())
# print(dictionary.shape) #(ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®æ•°,ã€€ç‰¹å¾´é‡ã®æ¬¡å…ƒæ•°)


# encode(x) ã‚’å‘¼ã³å‡ºã—ã€pre_codesï¼ˆæ´»æ€§åŒ–é–¢æ•°é©ç”¨å‰ã®å‡ºåŠ›ï¼‰ã¨ codesï¼ˆæœ€çµ‚çš„ãªæ½œåœ¨è¡¨ç¾ï¼‰ã‚’å–å¾—ã€‚
# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæ½œåœ¨è¡¨ç¾ z ã‚’ç”¨ã„ã¦ã€è¾æ›¸å±¤ã§å…¥åŠ›ã®å†æ§‹æˆ