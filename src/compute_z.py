import pathlib
from multiprocessing import Pool

import numpy as np
import torch
from overcomplete.models import DinoV2, ResNet  # noqa: F401
from scipy.optimize import nnls
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torchvision.transforms import Compose
from tqdm import tqdm

# def compute_Z_for_all_images(D_star, X):
#     """D_star: shape (2048, 10000)
#     X:      shape (N, 2048)  # Næšã®ç”»åƒã‚’å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã—ãŸç‰¹å¾´
#     å‡ºåŠ›:   Z: shape (N, 10000) # å„ç”»åƒã”ã¨ã«10æ¬¡å…ƒã®éè² ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«
#     """
#     Z_list = []
#     for i in tqdm(range(X.shape[0])):
#         x_i = X[i]              # shape=(2048,)
#         z_i, _ = nnls(D_star, x_i)  # shape=(10000,)
#         Z_list.append(z_i)
#     Z = np.stack(Z_list, axis=0)   # shape=(N,10000)
#     return Z

def compute_single_nnls(args):
    """args: (D_star, x_i) ã®ã‚¿ãƒ—ãƒ«
    d_star: shape (2048, 10000)
    x_i:    shape (2048,)  # 1æšã®ç”»åƒã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«
    å‡ºåŠ›:   z_i: shape (10000,) # 1æšã®ç”»åƒã”ã¨ã«10000æ¬¡å…ƒã®éè² ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«.
    """
    d_star, x_i = args
    z_i, _ = nnls(d_star, x_i)
    return z_i

def compute_z_for_all_images(d_star, x, num_processes=None):
    """args:
    d_star: shape (2048, 10000)
    X:      shape (N, 2048)  # Næšã®ç”»åƒã‚’å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã—ãŸç‰¹å¾´
    å‡ºåŠ›:   Z: shape (N, 10000) # å„ç”»åƒã”ã¨ã«10000æ¬¡å…ƒã®éè² ä¿‚æ•°ãƒ™ã‚¯ãƒˆãƒ«.
    """
    # å„ç”»åƒã®ç‰¹å¾´ã‚’ (d_star, x_i) ã®ã‚¿ãƒ—ãƒ«ã¨ã—ã¦ã¾ã¨ã‚ã‚‹
    args = [(d_star, x[i]) for i in range(x.shape[0])]
    
    # multiprocessing.Pool ã‚’ç”¨ã„ãŸä¸¦åˆ—å‡¦ç†
    with Pool(processes=num_processes) as pool:
        # tqdmã§é€²æ—è¡¨ç¤º
        z_list = list(tqdm(pool.imap(compute_single_nnls, args), total=len(args)))
    
    z = np.stack(z_list, axis=0)   # shape=(N,10000)
    return z

def compute_z_for_single_image(d_star, x):
    """D_star: shape (2048, 10000)
    x:      shape (2048,) - ç”»åƒ1æšã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«.
    """
    z, _ = nnls(d_star, x)  # z ã¯ (10000,) ã®éè² è§£
    return z

# æ—¢å­˜ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def torch_to_numpy(tensor):
    """PyTorchã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’NumPyé…åˆ—ã«å¤‰æ›ã—ã¾ã™ã€‚
    GPUä¸Šã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’CPUã«ç§»å‹•ã—ã€NumPyé…åˆ—ã«å¤‰æ›ã—ã¾ã™ã€‚
    å…¥åŠ›:
        tensor: torch.Tensor - PyTorchã®ãƒ†ãƒ³ã‚½ãƒ«
    å‡ºåŠ›:
        numpy.ndarray - NumPyé…åˆ—.
    """
    try:
        return tensor.detach().cpu().numpy()
    except Exception:
        return np.array(tensor)

def select_patch_from_activations(activations, patch_index):
    """CNNã®å‡ºåŠ›ã‹ã‚‰æŒ‡å®šã®ãƒ‘ãƒƒãƒã‚’é¸æŠã—ã¾ã™.
    
    å…¥åŠ›:
      activations: torch.Tensor, shape (N, C, H, W)
      patch_index: tuple of int, (i, j) ã§é¸æŠã™ã‚‹ç©ºé–“ä½ç½®
    å‡ºåŠ›:
      selected: torch.Tensor, shape (N, C) 
                æŒ‡å®šã—ãŸãƒ‘ãƒƒãƒã®ç‰¹å¾´ï¼ˆå„ç”»åƒã«ã¤ã1ãƒ‘ãƒƒãƒåˆ†ã®ç‰¹å¾´ï¼‰.
    """
    N, C, H, W = activations.shape # noqa: N806
    i, j = patch_index
    if not (0 <= i < H and 0 <= j < W):
        raise ValueError(f"æŒ‡å®šã—ãŸãƒ‘ãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {patch_index} ã¯æœ‰åŠ¹ãªç¯„å›² (H, W)=({H},{W}) ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    return activations[:, :, i, j]


# --- ä½¿ç”¨ä¾‹ ---
if __name__ == '__main__':

    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆGPUãŒä½¿ãˆã‚‹å ´åˆã¯ 'cuda'ï¼‰
    device = 'cuda' if torch.cuda.is_available() else 'cpu'

    # Dataloader
    transform_resnet = Compose(
        [transforms.Resize(
        (224, 224),
        interpolation=transforms.InterpolationMode.BICUBIC, antialias=True),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5],
                            std=[0.5, 0.5, 0.5])
        ]
    )

    transform_dino = Compose(
                [transforms.Resize(
                    (224, 224),
                    interpolation=transforms.InterpolationMode.BICUBIC, antialias=True),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                    std=[0.229, 0.224, 0.225])])

    dataset = datasets.ImageFolder(
        root=pathlib.Path("data/imagenet/val/"), transform=transform_resnet
    )

    model = ResNet(device='cuda')
    model.eval().to(device)

    D = np.load("outputs/nmf/dictionary.npz")["arr_0"]
    print(D.shape)  # (10000, 2048)

    z_all = []
    for class_name, class_idx in tqdm(dataset.class_to_idx.items()):
        # æŒ‡å®šã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åé›†ã™ã‚‹
        indices = [i for i, (_, target) in enumerate(dataset.samples) if target == class_idx]
        if not indices:
            continue  # ã‚µãƒ³ãƒ—ãƒ«ãŒãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ï¼
        
        # è©²å½“ã‚¯ãƒ©ã‚¹ã®Subsetã‚’ä½œæˆã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ç”¨æ„
        subset = torch.utils.data.Subset(dataset, indices[:20])
        subset_loader = DataLoader(subset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)
        
        images_list = []
        for images, _ in subset_loader:
            images_list.append(images)

        # ãƒãƒƒãƒã”ã¨ã«é€£çµã—ã¦GPUã¸
        images_class = torch.cat(images_list, dim=0).cuda()
        print(images_class.shape) # torch.Size([1300, 3, 224, 224])
        # forward_featuresã§ç‰¹å¾´æŠ½å‡º
        activations = model.forward_features(images_class)
        print(activations.shape) # torch.Size([1300, 2048, 7, 7])

        activations_gap = activations.mean(dim=[2, 3])
        print(f"ã‚¯ãƒ©ã‚¹ {class_name}: activations_gap shape = {activations_gap.shape} ğŸ˜„")

        # Activations = rearrange(activations, 'n c h w -> (n h w) c')
        # print(f"ã‚¯ãƒ©ã‚¹ {class_name}: Activations shape = {Activations.shape} ğŸ˜„")

        activation_np = torch_to_numpy(activations_gap)  # GPUãƒ†ãƒ³ã‚½ãƒ«ã‚’CPU/NumPyã«å¤‰æ›
        z = compute_z_for_all_images(D.T, activation_np)
        print("z shape:", z.shape)  # z shape: (5, 10000)
        z_all.append(z)
    z_all = np.concatenate(z_all, axis=0)
    np.savez("outputs/nmf/z_all_imagenet.npz", z=z_all)
    print("outputs/nmf/z_all_imagenet shape:", z_all.shape) 